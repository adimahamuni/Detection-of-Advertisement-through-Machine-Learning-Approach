{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the classes\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd  \n",
    "\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "#Scraping using Beautiful Soup \n",
    "url = 'https://www.freetutorials.eu/investing-in-stocks-the-complete-course-11-hour-1/'\n",
    "source = requests.get(url)\n",
    "\n",
    "#Alternative\n",
    "\"\"\"r = requests.get(\"http://example.com/\", proxies=dict(\n",
    "    http=\"http://proxy_user:proxy_pass@104.255.255.255:port\",\n",
    "))\"\"\"\n",
    "\n",
    "\n",
    "plaintext = source.text\n",
    "soup = bs(plaintext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping the sites\n",
    "def find():\n",
    "    fw = open('src.txt','w')\n",
    "    for link in soup.findAll('script'):    \n",
    "        href = link.get('src')\n",
    "        if href != None:\n",
    "            fw.write(href)\n",
    "            fw.write('\\n')\n",
    "        \n",
    "    fw.close()\n",
    "        \n",
    "find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crawler\n",
    "flog = open('FinalOp.txt', 'r')\n",
    "fog = open('arg.txt', 'r')\n",
    "\n",
    "string = []\n",
    "substr = []\n",
    "\n",
    "for line in flog.readlines():\n",
    "    string.append(line)\n",
    "for line in fog.readlines():\n",
    "    substr.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = []\n",
    "\n",
    "#Classification into Ad/Non-Ad for attribute creation\n",
    "def search():\n",
    "    \n",
    "    res = False\n",
    "    for st in string:\n",
    "        st = st[:-2]\n",
    "        for sub in substr: \n",
    "            sub = sub[:-2]\n",
    "            if sub in st:\n",
    "                res = True\n",
    "                break\n",
    "            else:\n",
    "                res = False\n",
    "                \n",
    "        if res:\n",
    "            ad.append(\"ad\")\n",
    "        else:\n",
    "            ad.append(\"non-ad\")\n",
    "    \n",
    "    return ad\n",
    "\n",
    "search()        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creating the Dataset\n",
    "def create_ds():\n",
    "    records = []  \n",
    "    \n",
    "    fr = open('FinalOp.txt','r')\n",
    "    \n",
    "    for line in fr.readlines():\n",
    "        #line = line[:-2]\n",
    "        \n",
    "        lengthUrl = len(line)      #Length of the string\n",
    "        special_char = re.findall('[!@#$%^&*(),.?\":{}|<>]', str(line))      #Special Characters\n",
    "                \n",
    "        numberOfSpecial_chars = len(special_char)           #Number of special characters in the string\n",
    "        isLetterDigitLetter = isLDL(str(line))              #letter digit letter\n",
    "                \n",
    "        #number of Dot Occurences\n",
    "        dotOcc = 0\n",
    "        for i in special_char:\n",
    "            if i.__eq__(\".\"):\n",
    "                dotOcc += 1\n",
    "                \n",
    "        #Presence of Numeric Token\n",
    "        if bool(re.match('^(?=.*[0-9])',line)):\n",
    "            numToken = 1\n",
    "        else:\n",
    "            numToken = 0\n",
    "        \n",
    "        #Dash Count\n",
    "        dashCount = 0\n",
    "        for i in line:\n",
    "            if i.__eq__(\"-\"):\n",
    "                dashCount += 1\n",
    "            \n",
    "        #Tokens and Entropy\n",
    "        token = getTokens(str(line))\n",
    "        entr = entropy(token)           #Alphabet Entropy\n",
    "        \n",
    "        #Max Token Length and Average Token Length\n",
    "        maxLength = 0\n",
    "        total = 0\n",
    "        countToken = 0\n",
    "        for item in token:\n",
    "            lengthToken = len(item)\n",
    "            \n",
    "            #Average Token Length\n",
    "            total += lengthToken\n",
    "            countToken += 1\n",
    "            avgLength = total/countToken\n",
    "            \n",
    "            #Max Token Length\n",
    "            if lengthToken > maxLength:\n",
    "                maxLength = lengthToken\n",
    "\n",
    "        records.append((line,lengthUrl,numToken,special_char,numberOfSpecial_chars,dotOcc,dashCount,isLetterDigitLetter,token,entr, maxLength,avgLength,countToken))\n",
    "        \n",
    "    #Dataframe       \n",
    "    df = pd.DataFrame(records, columns=['URL','Length-of-url','Numeric Token','Special_chars','Number of Special Characters','Number of Dot Occurences','Dash Count','LetterDigitLetter','Tokens','Alphabet Entropy','Max Token Length','Average Token Length','URL Token Count'])\n",
    "    df['Ads_Class'] = ad\n",
    "    \n",
    "    #Converting to CSV\n",
    "    df.to_csv('Dataset.csv',index=False,encoding='utf-8')\n",
    "    \n",
    "create_ds()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Letter Digit Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Letter Digit Letter\n",
    "def isLDL(s):\n",
    "    strng = []\n",
    "    strng.extend(s.split(\"/\"))\n",
    "    for i in strng:        \n",
    "        if bool(re.match('^(?=.*[0-9])(?=.*[a-zA-Z]$)',str(i))):\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Alphabet Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alphabet Entropy\n",
    "def entropy(s):\n",
    "\tp, lns = Counter(s), float(len(s))\n",
    "\treturn -sum( count/lns * math.log(count/lns, 2) for count in p.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Token Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokens(input):\n",
    "\ttokensBySlash = str(input.encode('utf-8')).split('/')\t#get tokens after splitting by slash\n",
    "\tallTokens = []\n",
    "\tfor i in tokensBySlash:\n",
    "\t\ttokens = str(i).split('-')\t#get tokens after splitting by dash\n",
    "\t\ttokensByDot = []\n",
    "\t\tfor j in range(0,len(tokens)):\n",
    "\t\t\ttempTokens = str(tokens[j]).split('.')\t#get tokens after splitting by dot\n",
    "\t\t\ttokensByDot = tokensByDot + tempTokens\n",
    "\t\tallTokens = allTokens + tokens + tokensByDot\n",
    "\tallTokens = list(set(allTokens))\t#remove redundant tokens\n",
    "\tif 'com' in allTokens:\n",
    "\t\tallTokens.remove('com')\t#removing .com since it occurs a lot of times and it should not be included in our features\n",
    "\treturn allTokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
